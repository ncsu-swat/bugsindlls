,Filter:,is:issue is:closed created:2024-02-25..2024-03-27 linked:pr ,Total Reproduced:,14,,,,,,,,,,
Issue #,PR #,Title,Reproduced,Issue Status,Device,API,Reported,Buggy Version,Nightly,Buggy File(s),Buggy Function(s),Remarks,Issue Link,PR Link
122594,,There is a comment error in test_transformers.py,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/122594,
122521,,UserWarning when using Tensor Model Parallel libraries (megatron and fairscale),No,Closed,,,,,,,,"Skipped: bug describes a warning, not an exception",https://github.com/pytorch/pytorch/issues/122521,
122445,,allow storage to be created for ort,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/122445,
122427,,MPS: Implement index_select() on complex value,No,Closed,GPU,Metal,,,,,,TODO,https://github.com/pytorch/pytorch/issues/122427,
122407,,Mergebot should send a cleaner message when [no ci] message added to the PR commit,No,Closed,,,,,,,,Skipped: related to building,https://github.com/pytorch/pytorch/issues/122407,
122296,122298,torch compile item() cannot convert symbols to int error,Yes,Closed,GPU,CUDA,03/20/2024,2.4.0.dev20240317,Yes,"torch/_inductor/compile_fx.py,torch/_inductor/graph.py","fx_codegen_and_compile(),run_node()",,https://github.com/pytorch/pytorch/issues/122296,https://github.com/pytorch/pytorch/pull/122298
122283,,[inductor][cpu] pyhpc_equation_of_state fp32 static shape default/cpp wrapper multiple thread performance test crashed,No,Closed,,,,,,,,Skipped: generated based on test failure,https://github.com/pytorch/pytorch/issues/122283,
122181,,[dort][dynamo_export] Wrong model for phi backward graph,No,Closed,,,,,,,,Could not reproduce,https://github.com/pytorch/pytorch/issues/122181,
122166,,[ONNX] Dispatcher does not handle list correctly when the first element is None,No,Closed,,,,,,,,Skipped: could not find code to reproduce bug,https://github.com/pytorch/pytorch/issues/122166,
122126,122149,split_with_sizes with unbacked SymInt results in buffers that cannot be materialized for extern calls,Yes,Closed,CPU,,03/18/2024,2.4.0.dev20240320,Yes,"torch/_inductor/ir.py,torch/_inductor/lowering.py","SliceView.create(),slice_()",,https://github.com/pytorch/pytorch/issues/122126,https://github.com/pytorch/pytorch/pull/122149
122085,122815,CUDA Being Initiated Early After Importing Certain Libraries on Nightly Build,Yes,Closed,GPU,CUDA,03/18/2024,2.4.0.dev20240317,Yes,torch/cuda/__init__.py,device_count(),,https://github.com/pytorch/pytorch/issues/122085,https://github.com/pytorch/pytorch/pull/122815
122026,,Memory violation in chunk_cat_cuda_kernel in test_out__chunk_cat_cuda_float32 on A100 and H100,No,Closed,,,,,,,,Skipped: mentions specific gpu models and internally discovered,https://github.com/pytorch/pytorch/issues/122026,
122008,,DISABLED test_hparams_string (__main__.TestTensorBoardSummary),No,Closed,,,,,,,,Skipped: related to dependency mismatch,https://github.com/pytorch/pytorch/issues/122008,
121986,,[ONNX] ONNX model has mismatching data type when Torch model and checkpoint dtype mismatches,No,Closed,,,,,,,,Could not reproduce,https://github.com/pytorch/pytorch/issues/121986,
121950,,DISABLED test_out__chunk_cat_cuda_float32 (__main__.TestCommonCUDA),No,Closed,,,,,,,,Skipped: auto generated by bot based on test failure,https://github.com/pytorch/pytorch/issues/121950,
121946,,DISABLED test_hparams_number (__main__.TestTensorBoardSummary),No,Closed,,,,,,,,Skipped: generated based on test failure,https://github.com/pytorch/pytorch/issues/121946,
121927,,DISABLED test_hparams_bool (__main__.TestTensorBoardSummary),No,Closed,,,,,,,,Skipped: generated based on test failure,https://github.com/pytorch/pytorch/issues/121927,
121798,,"what is the match numpy verison, can not build from source",No,Closed,,,,,,,,Skipped: build related issues,https://github.com/pytorch/pytorch/issues/121798,
121783,,The warning message in aten/src/ATen/native/transformers/sdp_utils_cpp.h::check_for_attn_mask is a bit confusing.,No,Closed,,,,,,,,Skipped: found from source code,https://github.com/pytorch/pytorch/issues/121783,
121770,,Typo On Torch.Sparse Page,No,Closed,,,,,,,,Skipped: typo fixing on documentation,https://github.com/pytorch/pytorch/issues/121770,
121654,,"[BE] De-dup run_subtests from common_dtensor.py, common_fsdp.py",No,Closed,,,,,,,,Skipped: duplicate test removed,https://github.com/pytorch/pytorch/issues/121654,
121649,,guard on tensor parallelism test examples,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/121649,
121647,,torch._int_mm on CPU,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/121647,
121593,,reduce_on_plateau_scheduler.h missing from optim.h in libtorch ?,No,Closed,,,,,,,,Skipped: related to building,https://github.com/pytorch/pytorch/issues/121593,
121591,,Running lintrunner init under Python3.8 got error: No matching distribution found for torchfix==0.4.0,No,Closed,,,,,,,,Skipped: related to dependencies,https://github.com/pytorch/pytorch/issues/121591,
121583,123289,RuntimeError: Undefined type BFloat16 from matmul above certain sizes (maybe MPS only),Yes,Closed,GPU,Metal,03/09/2024,2.3.0.dev20240309,Yes,"aten/src/ATen/native/mps/OperationUtils.mm, aten/src/ATen/native/mps/operations/LinearAlgebra.mm","scalarToMetalTypeString(), dot_product(), compileLinalgOpLibrary()",,https://github.com/pytorch/pytorch/issues/121583,https://github.com/pytorch/pytorch/pull/123289
121558,,Investigate NaNs in FlashAttention,No,Closed,,,,,,,,Could not reproduce,https://github.com/pytorch/pytorch/issues/121558,
121507,,Make builds repeatable multiple times from same git checkout,No,Closed,,,,,,,,Skipped: related to building,https://github.com/pytorch/pytorch/issues/121507,
121479,,device_resource_id is missing in FunctionEvent,No,Closed,,,,,,,,Skipped: found from source code,https://github.com/pytorch/pytorch/issues/121479,
121320,121341,h2d non-blocking copy with type conversion doesn't respect stream semantics,Yes,Closed,GPU,CUDA,03/06/2024,2.3.0.dev20240310,Yes,aten/src/ATen/native/cuda/Copy.cu,copy_kernel_cuda(),,https://github.com/pytorch/pytorch/issues/121320,https://github.com/pytorch/pytorch/pull/121341
121300,,torch.set_default_dtype(d) outdated?,No,Closed,,,,,,,,Skipped: related to documentation,https://github.com/pytorch/pytorch/issues/121300,
121289,,cpu_fallback for aten::triu_indices on custom device crashed,No,Closed,,,,,,,,Could not reproduce,https://github.com/pytorch/pytorch/issues/121289,
121253,121953,[torch.compile][freezing] addmm results in a significant decrease in accuracy,Yes,Closed,GPU,CUDA,03/05/2024,2.3.0.dev20240301,Yes,torch/_inductor/fx_passes/mkldnn_fusion.py,_is_packable_linear(),,https://github.com/pytorch/pytorch/issues/121253,https://github.com/pytorch/pytorch/pull/121953
121174,122083,[torch.compile] fuse_attention returns inconsistent value for the model,Yes,Closed,CPU,,03/04/2024,2.4.0.dev20240318,Yes,torch/_inductor/lowering.py,sdpa_constraint(),,https://github.com/pytorch/pytorch/issues/121174,https://github.com/pytorch/pytorch/pull/122083
121138,121156,Memory leak when attempting to turn ascii-encoded data from an hdf5 file into a torch tensor in a try-except block,Yes,Closed,CPU,,03/04/2024,1.12.1,No,torch/csrc/utils/tensor_numpy.cpp,tensor_from_numpy(),,https://github.com/pytorch/pytorch/issues/121138,https://github.com/pytorch/pytorch/pull/121156
121126,,The recorded step number in profiler is wrong,No,Closed,,,,,,,,Could not reproduce,https://github.com/pytorch/pytorch/issues/121126,
121100,,torch.onnx.dynamo_export complex number error,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/121100,
121093,121298,Segmentation Fault in torch._C._nn.replication_pad2d with Incorrect Inputs,Yes,Closed,GPU,CUDA,03/03/2024,2.3.0.dev20240220,Yes,aten/src/ATen/native/ReplicationPadding.cpp,"replication_pad1d(),replication_pad2d(),replication_pad3d()",,https://github.com/pytorch/pytorch/issues/121093,https://github.com/pytorch/pytorch/pull/121298
120998,121786,torch.compile fails with .view(dtype),Yes,Closed,GPU,CUDA,03/01/2024,2.1.2,No,torch/_inductor/lowering.py,to_dtype_bitcast(),,https://github.com/pytorch/pytorch/issues/120998,https://github.com/pytorch/pytorch/pull/121786
120922,,DISABLED test_dispatch_meta_outplace_nn_functional_scaled_dot_product_attention_cuda_float32 (__main__.TestMetaCUDA),No,Closed,,,,,,,,Skipped: disabled tests,https://github.com/pytorch/pytorch/issues/120922,
120921,,DISABLED test_dispatch_symbolic_meta_outplace_all_strides_nn_functional_scaled_dot_product_attention_cuda_float32 (__main__.TestMetaCUDA),No,Closed,,,,,,,,Skipped: disabled tests,https://github.com/pytorch/pytorch/issues/120921,
120918,,[ONNX] test_fx_op_consistency.py some cases success without running,No,Closed,,,,,,,,Skipped: found from source code,https://github.com/pytorch/pytorch/issues/120918,
120903,120987,INTERNAL ASSERT FAILED,Yes,Closed,CPU,,02/29/2024,2.2.0,No,aten/src/ATen/native/quantized/FakeQuantPerChannelAffine.cpp,fake_quantize_per_channel_affine_cachemask(),,https://github.com/pytorch/pytorch/issues/120903,https://github.com/pytorch/pytorch/pull/120987
120899,122785,Inconsistent Behavior of torch.clamp with NaN Values on MPS Device,Yes,Closed,GPU,Metal,02/29/2024,2.2.1,No,aten/src/ATen/native/mps/operations/TensorCompare.mm,clamp_mps_graph(),,https://github.com/pytorch/pytorch/issues/120899,https://github.com/pytorch/pytorch/pull/122785
120889,,"Provide documentation for ""TORCHDYNAMO_EXTENDED_DEBUG""",No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/120889,
120875,121803,The result of torch.all is inconsistent between CPU and GPU,Yes,Closed,GPU,CUDA,02/28/2024,2.2.0,No,"aten/src/ATen/native/Copy.cpp, c10/util/TypeCast.h","copy_impl(), apply()",TODO,https://github.com/pytorch/pytorch/issues/120875,https://github.com/pytorch/pytorch/pull/121803
120869,,[inductor][cpu] quantization QAT/PTQ accuracy test meets crash,No,Closed,CPU,,,,,,,TODO,https://github.com/pytorch/pytorch/issues/120869,
120810,,Scaled-Dot-Product-Attention Has Broadcastable Mask,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/120810,
120803,120882,Floating Point Exception on Empty Input Tensor with torch.batch_norm_update_stats,Yes,Closed,CPU,,02/28/2024,torch-2.3.0.dev20240220,Yes,"aten/src/ATen/native/Normalization.cpp,aten/src/ATen/native/cuda/Normalization.cu",batch_norm_update_stats_cuda(),"Note: ""The issue is reproducible on Linux (Ubuntu), but not on the Mac M1."" - comment in issue",https://github.com/pytorch/pytorch/issues/120803,https://github.com/pytorch/pytorch/pull/120882
120794,,prod() is broken on ROCM when used on tensors of int type on gfx908,No,Closed,,,,,,,,Skipped: multiple AMD gpu of specific model required with complicated steps,https://github.com/pytorch/pytorch/issues/120794,
120788,,Operator performance plummets on PyTorch 2.2.1 Windows platform,No,Closed,,,,,,,,Skipped: a specific build of windows and an amd cpu required,https://github.com/pytorch/pytorch/issues/120788,
120762,,Segmentation Fault due to Invalid out_dim Type in torch.tensor.flatten,No,Closed,CPU,,,,,,,TODO (Note: it was reported on a nightly build that is not available anymore. Please try with a stable build e.g. 2.2.1 to see if it can be reproduced),https://github.com/pytorch/pytorch/issues/120762,
120716,,torch.optim.lr_scheduler.ConstantLR's description,No,Closed,,,,,,,,Skipped: related to documentation,https://github.com/pytorch/pytorch/issues/120716,
120702,,Uninformative errors in cudnn/Conv_v8.cpp,No,Closed,,,,,,,,Skipped: not a bug,https://github.com/pytorch/pytorch/issues/120702,
120699,,[Dynamo] Inconsistent code with and without TYPE_CHECKING,No,Closed,,,,,,,,Skipped: found from source code,https://github.com/pytorch/pytorch/issues/120699,
120651,,"1 Dynamo test are failing with ""type object 'torch.return_types.max' has no attribute '_field_defaults'"".",No,Closed,,,,,,,,Skipped: auto generated by bot based on test failure,https://github.com/pytorch/pytorch/issues/120651,
120647,,"2 Dynamo test are failing with ""invalid syntax (<unknown"".",No,Closed,,,,,,,,TODO (Note: it was reported on a nightly build that is not available anymore. Please try with a stable build to see if it can be reproduced),https://github.com/pytorch/pytorch/issues/120647,
120646,,"5 Dynamo test are failing with ""No module named 'torch.inference_mode'"".",No,Closed,,,,,,,,Skipped: auto generated by bot based on test failure,https://github.com/pytorch/pytorch/issues/120646,